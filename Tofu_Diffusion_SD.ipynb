{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByGXyiHZWM_q"
      },
      "source": [
        "# **Tofu Diffusion SD**\n",
        "\n",
        "**Tofu Diffusion is a fork of the Deforum notebook, made for single image generation**\\\n",
        "\\\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings). Notebook by [deforum](https://discord.gg/upmXXsrwZc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IJjzzkKlWM_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56cd4d85-dc86-4a02-bd70-e856044bc523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown **1. NVIDIA GPU**\n",
        "import subprocess, os, sys\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(f\"{sub_p_res[:-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA8-efH-WM_t"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vohUiWo-I2HQ",
        "outputId": "3d8fbeb9-e87c-403e-d9a0-398c652410c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "..setting up environment\n",
            "..installing triton and xformers\n",
            "..environment set up in 60 seconds\n"
          ]
        }
      ],
      "source": [
        "#@markdown **2. Environment Setup**\n",
        "import subprocess, time, gc, os, sys\n",
        "\n",
        "!mkdir -p /content/civitai_models\n",
        "\n",
        "def setup_environment():\n",
        "    start_time = time.time()\n",
        "    print_subprocess = False\n",
        "    use_xformers_for_colab = True\n",
        "    try:\n",
        "        ipy = get_ipython()\n",
        "    except:\n",
        "        ipy = 'could not get_ipython'\n",
        "    if 'google.colab' in str(ipy):\n",
        "        print(\"..setting up environment\")\n",
        "        \n",
        "        all_process = [\n",
        "            ['pip', 'install', 'omegaconf', 'einops==0.4.1', 'pytorch-lightning==1.7.8', 'torchmetrics', 'transformers', 'safetensors', 'kornia'],\n",
        "            ['git', 'clone', '-b', 'dev', 'https://github.com/deforum-art/deforum-stable-diffusion'],\n",
        "            ['pip', 'install', 'accelerate', 'ftfy', 'jsonmerge', 'matplotlib', 'resize-right', 'timm', 'torchdiffeq','scikit-learn','torchsde','open-clip-torch','numpngw'],\n",
        "        ]\n",
        "        for process in all_process:\n",
        "            running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if print_subprocess:\n",
        "                print(running)\n",
        "        with open('deforum-stable-diffusion/src/k_diffusion/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "        sys.path.extend([\n",
        "            'deforum-stable-diffusion/',\n",
        "            'deforum-stable-diffusion/src',\n",
        "        ])\n",
        "        if use_xformers_for_colab:\n",
        "\n",
        "            print(\"..installing triton and xformers\")\n",
        "\n",
        "            all_process = [['pip', 'install', 'triton', 'xformers']]\n",
        "            for process in all_process:\n",
        "                running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                if print_subprocess:\n",
        "                    print(running)\n",
        "    else:\n",
        "        sys.path.extend([\n",
        "            'src'\n",
        "        ])\n",
        "    end_time = time.time()\n",
        "    print(f\"..environment set up in {end_time-start_time:.0f} seconds\")\n",
        "    return\n",
        "\n",
        "setup_environment()\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import clip\n",
        "from IPython import display\n",
        "from types import SimpleNamespace\n",
        "from helpers.save_images import get_output_folder\n",
        "from helpers.settings import load_args\n",
        "from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
        "from helpers.model_load import make_linear_decode, load_model, get_model_output_paths\n",
        "from helpers.aesthetics import load_aesthetics_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchvision -y\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "IYyke-g-eKPB",
        "outputId": "b9fb5f74-b3a6-4242-81c7-e9804231acb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.15.2+cu118\n",
            "Uninstalling torchvision-0.15.2+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.2+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Collecting torch==2.0.1 (from torchvision)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.19 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1 torchvision-0.15.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvfuser",
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "#@markdown **3. CivitAI Model Setup**\n",
        "\n",
        "civitai_models_list = []\n",
        "civitai_model_path = \"\" #@param {type:\"string\"}\n",
        "civitai_model_name = \"\" #@param {type:\"string\"}\n",
        "civitai_model_type = \".safetensors\" #@param [\".safetensors\",\".ckpt\"]\n",
        "\n",
        "#@markdown\n",
        "#@markdown *Check your model type on CivitAI*\\\n",
        "#@markdown --- Pickletensor -> .ckpt \\\n",
        "#@markdown --- Safetensor -> .safetensors\n",
        "\n",
        "if not civitai_model_path:\n",
        "    display(HTML('<font color=\"red\">Link missing</font>'))\n",
        "elif not civitai_model_name:\n",
        "    display(HTML('<font color=\"red\">Name missing</font>'))\n",
        "else:\n",
        "    output = !wget -O /content/civitai_models/{civitai_model_name}{civitai_model_type} {civitai_model_path} && echo \"Download successful\" || echo \"Download failed\"\n",
        "\n",
        "output_list = list(output)\n",
        "    \n",
        "directory = \"/content/civitai_models\"\n",
        "files_in_directory = os.listdir(directory)\n",
        "civitai_models_list = [file for file in files_in_directory if file.endswith(\".ckpt\") or file.endswith(\".safetensors\")]\n",
        "\n",
        "#clear_output()\n",
        "\n",
        "#if output_list[-1] == \"Download successful\":\n",
        "#    display(HTML('<b><font color=\"green\">CivitAI model downloaded successfully!</font></b>'))\n",
        "#    print(f\"{civitai_model_name}{civitai_model_type}\")\n",
        "#    print(\"path = /content/civitai_models/\"f\"{civitai_model_name}{civitai_model_type}\")\n",
        "#else:\n",
        "#    print(\"Download failed\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bXa7p0CwVLlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "#@markdown **3. Civitai Model Setup**\n",
        "\n",
        "#@markdown *copy the download link of your model*\n",
        "\n",
        "civitai_models_list = []\n",
        "civitai_model_url = \"https://civitai.com/api/download/models/29460\" #@param {type:\"string\"}\n",
        "\n",
        "output = \"\" \n",
        "\n",
        "if not civitai_model_url:\n",
        "    display(HTML('<font color=\"red\">Link missing</font>'))\n",
        "else:\n",
        "    output = !cd /content/civitai_models/ && mkdir -p tmp && cd tmp && curl -LOJ {civitai_model_url} && mv * ../ && echo \"Download successful\" || echo \"Download failed, maybe the link is wrong?\"\n",
        "    print(f'{output[-1]}\\n')\n",
        "\n",
        "directory = \"/content/civitai_models\"\n",
        "files_in_directory = os.listdir(directory)\n",
        "civitai_models_list = [file for file in files_in_directory if file.endswith(\".ckpt\") or file.endswith(\".safetensors\")]\n",
        "for file in civitai_models_list: \n",
        "    print(f'{file}: {directory}/{file}')\n",
        "\n",
        "#clear_output()\n",
        "\n",
        "#if output_list[-1] == \"Download successful\":\n",
        "#    display(HTML('<b><font color=\"green\">CivitAI model downloaded successfully!</font></b>'))\n",
        "#    print(f\"{civitai_model_name}{civitai_model_type}\")\n",
        "#    print(\"path = /content/civitai_models/\"f\"{civitai_model_name}{civitai_model_type}\")\n",
        "#else:\n",
        "#    print(\"Download failed\")"
      ],
      "metadata": {
        "id": "3iI5GG7P8rQE",
        "outputId": "b716f822-931c-4b7a-9f23-11687a0fe270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful\n",
            "realisticVisionV20_v20.safetensors: /content/civitai_models/realisticVisionV20_v20.safetensors\n",
            "\n",
            "deliberate_v2.safetensors: /content/civitai_models/deliberate_v2.safetensors\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D2HQO-PWM_t"
      },
      "outputs": [],
      "source": [
        "#@markdown **4. Path Setup**\n",
        "\n",
        "def Root():\n",
        "    models_path = \"models\" \n",
        "    configs_path = \"configs\" \n",
        "    output_path = \"outputs\" \n",
        "    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "    models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
        "    output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
        "\n",
        "    #@markdown **5. Model Setup**\n",
        "    map_location = \"cuda\" \n",
        "    model_config = \"v1-inference.yaml\" \n",
        "    model_checkpoint =  \"custom\" #@param [\"custom\",\"v2-1_768-ema-pruned.ckpt\",\"v2-1_512-ema-pruned.ckpt\",\"768-v-ema.ckpt\",\"512-base-ema.ckpt\",\"Protogen_V2.2.ckpt\",\"v1-5-pruned.ckpt\",\"v1-5-pruned-emaonly.ckpt\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"wd-v1-3-float16.ckpt\"]\n",
        "    custom_config_path = \"\" \n",
        "    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "    return locals()\n",
        "\n",
        "root = Root()\n",
        "root = SimpleNamespace(**root)\n",
        "\n",
        "root.models_path, root.output_path = get_model_output_paths(root)\n",
        "root.model, root.device = load_model(root, load_on_run_all=True, check_sha256=True, map_location=root.map_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JxwhBwtWM_t"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "# List of items\n",
        "items = ['Option 1', 'Option 2', 'Option 3']\n",
        "\n",
        "# Create a Dropdown widget\n",
        "dropdown = widgets.Dropdown(options=items)\n",
        "\n",
        "# Display the widget\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "eS2UizLLjfnh",
        "outputId": "ad2f3ea6-5744-4bc5-fdf6-a019ab7431a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fd172e54926f4daa8e23a83a48781479",
            "f64d87a7b5064d8da2c86c721afaa758",
            "fc9c2003289a48e7bef4d063e326fe1f"
          ]
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(options=('Option 1', 'Option 2', 'Option 3'), value='Option 1')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd172e54926f4daa8e23a83a48781479"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E0tJVYA4WM_u"
      },
      "outputs": [],
      "source": [
        "def DeforumAnimArgs():\n",
        "\n",
        "    #@markdown ####**5. Load additional settings**\n",
        "    #@markdown *Don't forget to run this cell!*\n",
        "    animation_mode = 'None' \n",
        "    max_frames = 1000 \n",
        "    border = 'replicate' \n",
        "\n",
        "    ##@markdown ####**Motion Parameters:**\n",
        "    angle = \"0:(0)\"\n",
        "    zoom = \"0:(1.04)\"\n",
        "    translation_x = \"0:(10*sin(2*3.14*t/10))\"\n",
        "    translation_y = \"0:(0)\"\n",
        "    translation_z = \"0:(10)\"\n",
        "    rotation_3d_x = \"0:(0)\"\n",
        "    rotation_3d_y = \"0:(0)\"\n",
        "    rotation_3d_z = \"0:(0)\"\n",
        "    flip_2d_perspective = False \n",
        "    perspective_flip_theta = \"0:(0)\"\n",
        "    perspective_flip_phi = \"0:(t%15)\"\n",
        "    perspective_flip_gamma = \"0:(0)\"\n",
        "    perspective_flip_fv = \"0:(53)\"\n",
        "    noise_schedule = \"0: (0.02)\"\n",
        "    strength_schedule = \"0: (0.65)\"\n",
        "    contrast_schedule = \"0: (1.0)\"\n",
        "    hybrid_comp_alpha_schedule = \"0:(1)\" \n",
        "    hybrid_comp_mask_blend_alpha_schedule = \"0:(0.5)\"\n",
        "    hybrid_comp_mask_contrast_schedule = \"0:(1)\"\n",
        "    hybrid_comp_mask_auto_contrast_cutoff_high_schedule =  \"0:(100)\"\n",
        "    hybrid_comp_mask_auto_contrast_cutoff_low_schedule =  \"0:(0)\"\n",
        "\n",
        "    ##@markdown ####**Sampler Scheduling:**\n",
        "    enable_schedule_samplers = False \n",
        "    sampler_schedule = \"0:('euler'),10:('dpm2'),20:('dpm2_ancestral'),30:('heun'),40:('euler'),50:('euler_ancestral'),60:('dpm_fast'),70:('dpm_adaptive'),80:('dpmpp_2s_a'),90:('dpmpp_2m')\"\n",
        "\n",
        "    ##@markdown ####**Unsharp mask (anti-blur) Parameters:**\n",
        "    kernel_schedule = \"0: (5)\"\n",
        "    sigma_schedule = \"0: (1.0)\"\n",
        "    amount_schedule = \"0: (0.2)\"\n",
        "    threshold_schedule = \"0: (0.0)\"\n",
        "\n",
        "    ##@markdown ####**Coherence:**\n",
        "    color_coherence = 'Match Frame 0 LAB'\n",
        "    color_coherence_video_every_N_frames = 1 \n",
        "    color_force_grayscale = False \n",
        "    diffusion_cadence = '1' \n",
        "\n",
        "    ##@markdown ####**3D Depth Warping:**\n",
        "    use_depth_warping = True \n",
        "    midas_weight = 0.3\n",
        "    near_plane = 200\n",
        "    far_plane = 10000\n",
        "    fov = 40\n",
        "    padding_mode = 'border'\n",
        "    sampling_mode = 'bicubic'\n",
        "    save_depth_maps = False \n",
        "\n",
        "    ##@markdown ####**Video Input:**\n",
        "    video_init_path ='/content/video_in.mp4'\n",
        "    extract_nth_frame = 1\n",
        "    overwrite_extracted_frames = True \n",
        "    use_mask_video = False \n",
        "    video_mask_path ='/content/video_in.mp4'\n",
        "\n",
        "    ##@markdown ####**Hybrid Video for 2D/3D Animation Mode:**\n",
        "    hybrid_generate_inputframes = False \n",
        "    hybrid_use_first_frame_as_init_image = True \n",
        "    hybrid_motion = \"None\" \n",
        "    hybrid_motion_use_prev_img = False \n",
        "    hybrid_flow_method = \"DIS Medium\" \n",
        "    hybrid_composite = False \n",
        "    hybrid_comp_mask_type = \"None\" \n",
        "    hybrid_comp_mask_inverse = False \n",
        "    hybrid_comp_mask_equalize = \"None\"\n",
        "    hybrid_comp_mask_auto_contrast = False \n",
        "    hybrid_comp_save_extra_frames = False \n",
        "    hybrid_use_video_as_mse_image = False\n",
        "\n",
        "    ##@markdown ####**Interpolation:**\n",
        "    interpolate_key_frames = False \n",
        "    interpolate_x_frames = 4 \n",
        "    \n",
        "    ##@markdown ####**Resume Animation:**\n",
        "    resume_from_timestring = False\n",
        "    resume_timestring = \"20220829210106\" \n",
        "\n",
        "    return locals()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9fly1RIWM_u"
      },
      "outputs": [],
      "source": [
        "## 6. Prompts ##\n",
        "\n",
        "# positive prompts\n",
        "cond_prompts = {\n",
        "    1: \"(best resolution, 4k, best detail), perfect face, latina, cute round face, thick lips, 30 years, punk makeupgreen eyes, black bikini, perfect body, Cinematic lighting\",\n",
        "    2: \"photograph of a model, delicate features, beautiful face, dreadlocked hair, long bangs, long ponytail, brown eyes\",\n",
        "}\n",
        "\n",
        "# negative prompts\n",
        "uncond_prompts = {\n",
        "    1: \"(lowres, bad quality), deformed body, deformed face, ugly, extra fingers, extra limbs, bad hands\",\n",
        "    2: \"(lowres, bad quality), deformed body, deformed face, ugly, extra fingers, extra limbs, bad hands\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVzhbmizWM_u"
      },
      "outputs": [],
      "source": [
        "##@markdown **Load Settings**\n",
        "override_settings_with_file = False \n",
        "settings_file = \"custom\" \n",
        "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"\n",
        "#@markdown **7. Run**\n",
        "def DeforumArgs():\n",
        "    #@markdown **Image Settings**\n",
        "    W = \"512\" #@param [512, 640, 768, 896, 1024]\n",
        "    H = 768 #@param [512, 640, 768, 896, 1024]\n",
        "    W = int(W)\n",
        "    H = int(H)\n",
        "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
        "    bit_depth_output = 8 #@param [8, 16, 32] {type:\"raw\"}\n",
        "\n",
        "    #@markdown **Sampling Settings**\n",
        "    seed = -1 #@param\n",
        "    sampler = 'ddim' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_a\", \"dpmpp_2m\"]\n",
        "    steps = 30 #@param\n",
        "    scale = 15 #@param\n",
        "    ddim_eta = 0.0\n",
        "    dynamic_threshold = None\n",
        "    static_threshold = None   \n",
        "\n",
        "    ##@markdown **Save & Display Settings**\n",
        "    save_samples = True \n",
        "    save_settings = True \n",
        "    display_samples = True \n",
        "    save_sample_per_step = False \n",
        "    show_sample_per_step = False \n",
        "\n",
        "    #@markdown **Batch Settings**\n",
        "    n_batch = 1 #@param\n",
        "    n_samples = 1 #@param\n",
        "    batch_name = \"StableArt\" #@param {type:\"string\"}\n",
        "    filename_format = \"{timestring}_{index}_{prompt}.png\" \n",
        "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\",\"ladder\",\"alternate\"]\n",
        "    seed_iter_N = 1 \n",
        "    make_grid = False #@param {type:\"boolean\"}\n",
        "    grid_rows = 2 #@param \n",
        "    outdir = get_output_folder(root.output_path, batch_name)\n",
        "\n",
        "    #@markdown **Initial Image Settings**\n",
        "    use_init = False #@param {type:\"boolean\"}\n",
        "    strength = 0.65 #@param {type:\"number\"}\n",
        "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
        "    init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
        "    add_init_noise = False #@param {type:\"boolean\"}\n",
        "    init_noise = 0.01 #@param\n",
        "    # Whiter areas of the mask are areas that change more\n",
        "    use_mask = False\n",
        "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
        "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\" \n",
        "    invert_mask = False \n",
        "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
        "    mask_brightness_adjust = 1.0  \n",
        "    mask_contrast_adjust = 1.0  \n",
        "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
        "    overlay_mask = True  \n",
        "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
        "    mask_overlay_blur = 5 \n",
        "\n",
        "    ##@markdown **Exposure/Contrast Conditional Settings**\n",
        "    mean_scale = 0 \n",
        "    var_scale = 0 \n",
        "    exposure_scale = 0 \n",
        "    exposure_target = 0.5 \n",
        "\n",
        "    ##@markdown **Color Match Conditional Settings**\n",
        "    colormatch_scale = 0 \n",
        "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\"\n",
        "    colormatch_n_colors = 4 \n",
        "    ignore_sat_weight = 0 \n",
        "\n",
        "    ##@markdown **CLIP\\Aesthetics Conditional Settings**\n",
        "    clip_name = 'ViT-L/14' \n",
        "    clip_scale = 0 \n",
        "    aesthetics_scale = 0 \n",
        "    cutn = 1 \n",
        "    cut_pow = 0.0001\n",
        "\n",
        "    ##@markdown **Other Conditional Settings**\n",
        "    init_mse_scale = 0 \n",
        "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" \n",
        "    blue_scale = 0 \n",
        "    \n",
        "    ##@markdown **Conditional Gradient Settings**\n",
        "    gradient_wrt = 'x0_pred' \n",
        "    gradient_add_to = 'both' \n",
        "    decode_method = 'linear' \n",
        "    grad_threshold_type = 'dynamic' \n",
        "    clamp_grad_threshold = 0.2 \n",
        "    clamp_start = 0.2 \n",
        "    clamp_stop = 0.01 \n",
        "    grad_inject_timing = list(range(1,10)) \n",
        "\n",
        "    ##@markdown **Speed vs VRAM Settings**\n",
        "    cond_uncond_sync = True \n",
        "    precision = 'autocast' \n",
        "    C = 4\n",
        "    f = 8\n",
        "\n",
        "    cond_prompt = \"\"\n",
        "    cond_prompts = \"\"\n",
        "    uncond_prompt = \"\"\n",
        "    uncond_prompts = \"\"\n",
        "    timestring = \"\"\n",
        "    init_latent = None\n",
        "    init_sample = None\n",
        "    init_sample_raw = None\n",
        "    mask_sample = None\n",
        "    init_c = None\n",
        "    seed_internal = 0\n",
        "\n",
        "    return locals()\n",
        "\n",
        "args_dict = DeforumArgs()\n",
        "anim_args_dict = DeforumAnimArgs()\n",
        "\n",
        "if override_settings_with_file:\n",
        "    load_args(args_dict, anim_args_dict, settings_file, custom_settings_file, verbose=False)\n",
        "\n",
        "args = SimpleNamespace(**args_dict)\n",
        "anim_args = SimpleNamespace(**anim_args_dict)\n",
        "\n",
        "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "args.strength = max(0.0, min(1.0, args.strength))\n",
        "\n",
        "# Load clip model if using clip guidance\n",
        "if (args.clip_scale > 0) or (args.aesthetics_scale > 0):\n",
        "    root.clip_model = clip.load(args.clip_name, jit=False)[0].eval().requires_grad_(False).to(root.device)\n",
        "    if (args.aesthetics_scale > 0):\n",
        "        root.aesthetics_model = load_aesthetics_model(args, root)\n",
        "\n",
        "if args.seed == -1:\n",
        "    args.seed = random.randint(0, 2**32 - 1)\n",
        "if not args.use_init:\n",
        "    args.init_image = None\n",
        "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
        "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
        "    args.sampler = 'klms'\n",
        "if args.sampler != 'ddim':\n",
        "    args.ddim_eta = 0\n",
        "\n",
        "if anim_args.animation_mode == 'None':\n",
        "    anim_args.max_frames = 1\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    args.use_init = True\n",
        "\n",
        "# clean up unused memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# dispatch to appropriate renderer\n",
        "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
        "    render_animation(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    render_input_video(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "elif anim_args.animation_mode == 'Interpolation':\n",
        "    render_interpolation(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "else:\n",
        "    render_image_batch(root, args, cond_prompts, uncond_prompts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install -i https://download.pytorch.org/whl/cu118 torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "Jg78DAczafXP",
        "outputId": "60cf0bf6-eca7-4002-d1a3-f39acc692db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.0\n",
            "Uninstalling torch-2.0.0:\n",
            "  Successfully uninstalled torch-2.0.0\n",
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.19 requires torch==2.0.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1+cu118 torchvision-0.15.2+cu118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvfuser",
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('dsd')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b7e04c8a9537645cbc77fa0cbde8069bc94e341b0d5ced104651213865b24e58"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd172e54926f4daa8e23a83a48781479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Option 1",
              "Option 2",
              "Option 3"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_f64d87a7b5064d8da2c86c721afaa758",
            "style": "IPY_MODEL_fc9c2003289a48e7bef4d063e326fe1f"
          }
        },
        "f64d87a7b5064d8da2c86c721afaa758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9c2003289a48e7bef4d063e326fe1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}