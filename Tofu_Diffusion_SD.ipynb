{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByGXyiHZWM_q"
      },
      "source": [
        "# **Tofu Diffusion SD**\n",
        "\n",
        "**Tofu Diffusion v1.0.0** is a fork of the [Deforum](https://github.com/deforum-art/deforum-stable-diffusion) notebook, made for single image generation. This notebook was customized by tofu.diffusion@gmail.com\n",
        "\n",
        "\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj√∂rn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IJjzzkKlWM_s"
      },
      "outputs": [],
      "source": [
        "#@markdown **1. NVIDIA GPU**\n",
        "import subprocess, os, sys\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(f\"{sub_p_res[:-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA8-efH-WM_t"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vohUiWo-I2HQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **2. Environment Setup**\n",
        "import subprocess, time, gc, os, sys\n",
        "\n",
        "def setup_environment():\n",
        "    try:\n",
        "        ipy = get_ipython()\n",
        "    except:\n",
        "        ipy = 'could not get_ipython'\n",
        "\n",
        "    if 'google.colab' in str(ipy):\n",
        "        start_time = time.time()\n",
        "        packages = [\n",
        "            'triton xformers==0.0.20',\n",
        "            'einops==0.4.1 pytorch-lightning==1.7.7 torchdiffeq==0.2.3 torchsde==0.2.5',\n",
        "            'ftfy timm transformers open-clip-torch omegaconf torchmetrics==0.11.4',\n",
        "            'safetensors kornia accelerate jsonmerge matplotlib resize-right',\n",
        "            'scikit-learn numpngw pydantic'\n",
        "        ]\n",
        "        for package in packages:\n",
        "            print(f\"..installing {package}\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + package.split())\n",
        "        if not os.path.exists(\"deforum-stable-diffusion\"):\n",
        "            subprocess.check_call(['git', 'clone', '-b', '0.7.1', 'https://github.com/deforum-art/deforum-stable-diffusion.git'])\n",
        "        else:\n",
        "            print(f\"..deforum-stable-diffusion already exists\")\n",
        "        with open('deforum-stable-diffusion/src/k_diffusion/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "        sys.path.extend(['deforum-stable-diffusion/','deforum-stable-diffusion/src',])\n",
        "        end_time = time.time()\n",
        "        print(f\"..environment set up in {end_time-start_time:.0f} seconds\")\n",
        "    else:\n",
        "        sys.path.extend(['src'])\n",
        "        print(\"..skipping setup\")\n",
        "\n",
        "setup_environment()\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import clip\n",
        "from IPython import display\n",
        "from types import SimpleNamespace\n",
        "from helpers.save_images import get_output_folder\n",
        "from helpers.settings import load_args\n",
        "from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
        "from helpers.model_load import make_linear_decode, load_model, get_model_output_paths\n",
        "from helpers.aesthetics import load_aesthetics_model\n",
        "from helpers.prompts import Prompts\n",
        "\n",
        "!mkdir -p /content/civitai_models/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "#@markdown **3. Civitai Model Setup**\\\n",
        "#@markdown *copy the download link adress from civitai.com - works with versions SD 1.4 - 1.5 - 2.0 - 2.1*\n",
        "\n",
        "folder_path = '/content/civitai_models/'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "civitai_models_list = []\n",
        "civitai_model_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "output = \"\"\n",
        "\n",
        "if not civitai_model_url:\n",
        "    display(HTML('<font color=\"red\">Link missing</font>'))\n",
        "else:\n",
        "    output = !cd /content/civitai_models/ && mkdir -p tmp && cd tmp && curl -LOJ {civitai_model_url} && mv * ../ && echo \"Download successful\" || echo \"Download failed, maybe the link is wrong?\"\n",
        "    print(f'{output[-1]}\\n')\n",
        "\n",
        "directory = \"/content/civitai_models\"\n",
        "files_in_directory = os.listdir(directory)\n",
        "civitai_models_list = [file for file in files_in_directory if file.endswith(\".ckpt\") or file.endswith(\".safetensors\")]\n",
        "for file in civitai_models_list:\n",
        "    print(f'{file}: {directory}/{file}')"
      ],
      "metadata": {
        "id": "3iI5GG7P8rQE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D2HQO-PWM_t",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **4. Path Setup**\n",
        "\n",
        "def Root():\n",
        "    models_path = \"models\"\n",
        "    configs_path = \"configs\"\n",
        "    output_path = \"outputs\"\n",
        "    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "    models_path_gdrive = \"/content/drive/MyDrive/AI/models\"\n",
        "    output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\"\n",
        "\n",
        "    #@markdown **5. Model Setup**\n",
        "    map_location = \"cuda\"\n",
        "    #@markdown *In **model_config** if the model you are using is based on SD 1.4 or 1.5 choose (v1-inference.yaml)*\\\n",
        "    #@markdown *if it is based on SD 2.0 or 2.1 use (v2-interference-v.yaml)*\n",
        "    model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v2-inference.yaml\",\"v2-inference-v.yaml\",\"v1-inference.yaml\"]\n",
        "    model_checkpoint =  \"custom\" #@param [\"custom\",\"v2-1_768-ema-pruned.ckpt\",\"v2-1_512-ema-pruned.ckpt\",\"768-v-ema.ckpt\",\"512-base-ema.ckpt\",\"Protogen_V2.2.ckpt\",\"v1-5-pruned.ckpt\",\"v1-5-pruned-emaonly.ckpt\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"wd-v1-3-float16.ckpt\"]\n",
        "    custom_config_path = \"\"\n",
        "    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "    return locals()\n",
        "\n",
        "root = Root()\n",
        "root = SimpleNamespace(**root)\n",
        "\n",
        "root.models_path, root.output_path = get_model_output_paths(root)\n",
        "root.model, root.device = load_model(root, load_on_run_all=True, check_sha256=True, map_location=root.map_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JxwhBwtWM_t"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E0tJVYA4WM_u"
      },
      "outputs": [],
      "source": [
        "def DeforumAnimArgs():\n",
        "\n",
        "    #@markdown ####**6. Load additional settings**\n",
        "    #@markdown *Don't forget to run this cell!*\n",
        "    animation_mode = 'None'\n",
        "    max_frames = 1000\n",
        "    border = 'replicate'\n",
        "\n",
        "    ##@markdown ####**Motion Parameters:**\n",
        "    angle = \"0:(0)\"\n",
        "    zoom = \"0:(1.04)\"\n",
        "    translation_x = \"0:(10*sin(2*3.14*t/10))\"\n",
        "    translation_y = \"0:(0)\"\n",
        "    translation_z = \"0:(10)\"\n",
        "    rotation_3d_x = \"0:(0)\"\n",
        "    rotation_3d_y = \"0:(0)\"\n",
        "    rotation_3d_z = \"0:(0)\"\n",
        "    flip_2d_perspective = False\n",
        "    perspective_flip_theta = \"0:(0)\"\n",
        "    perspective_flip_phi = \"0:(t%15)\"\n",
        "    perspective_flip_gamma = \"0:(0)\"\n",
        "    perspective_flip_fv = \"0:(53)\"\n",
        "    noise_schedule = \"0: (0.02)\"\n",
        "    strength_schedule = \"0: (0.65)\"\n",
        "    contrast_schedule = \"0: (1.0)\"\n",
        "    hybrid_comp_alpha_schedule = \"0:(1)\"\n",
        "    hybrid_comp_mask_blend_alpha_schedule = \"0:(0.5)\"\n",
        "    hybrid_comp_mask_contrast_schedule = \"0:(1)\"\n",
        "    hybrid_comp_mask_auto_contrast_cutoff_high_schedule =  \"0:(100)\"\n",
        "    hybrid_comp_mask_auto_contrast_cutoff_low_schedule =  \"0:(0)\"\n",
        "\n",
        "    ##@markdown ####**Sampler Scheduling:**\n",
        "    enable_schedule_samplers = False\n",
        "    sampler_schedule = \"0:('euler'),10:('dpm2'),20:('dpm2_ancestral'),30:('heun'),40:('euler'),50:('euler_ancestral'),60:('dpm_fast'),70:('dpm_adaptive'),80:('dpmpp_2s_a'),90:('dpmpp_2m')\"\n",
        "\n",
        "    ##@markdown ####**Unsharp mask (anti-blur) Parameters:**\n",
        "    kernel_schedule = \"0: (5)\"\n",
        "    sigma_schedule = \"0: (1.0)\"\n",
        "    amount_schedule = \"0: (0.2)\"\n",
        "    threshold_schedule = \"0: (0.0)\"\n",
        "\n",
        "    ##@markdown ####**Coherence:**\n",
        "    color_coherence = 'Match Frame 0 LAB'\n",
        "    color_coherence_video_every_N_frames = 1\n",
        "    color_force_grayscale = False\n",
        "    diffusion_cadence = '1'\n",
        "\n",
        "    ##@markdown ####**3D Depth Warping:**\n",
        "    use_depth_warping = True\n",
        "    midas_weight = 0.3\n",
        "    near_plane = 200\n",
        "    far_plane = 10000\n",
        "    fov = 40\n",
        "    padding_mode = 'border'\n",
        "    sampling_mode = 'bicubic'\n",
        "    save_depth_maps = False\n",
        "\n",
        "    ##@markdown ####**Video Input:**\n",
        "    video_init_path ='/content/video_in.mp4'\n",
        "    extract_nth_frame = 1\n",
        "    overwrite_extracted_frames = True\n",
        "    use_mask_video = False\n",
        "    video_mask_path ='/content/video_in.mp4'\n",
        "\n",
        "    ##@markdown ####**Hybrid Video for 2D/3D Animation Mode:**\n",
        "    hybrid_generate_inputframes = False\n",
        "    hybrid_use_first_frame_as_init_image = True\n",
        "    hybrid_motion = \"None\"\n",
        "    hybrid_motion_use_prev_img = False\n",
        "    hybrid_flow_method = \"DIS Medium\"\n",
        "    hybrid_composite = False\n",
        "    hybrid_comp_mask_type = \"None\"\n",
        "    hybrid_comp_mask_inverse = False\n",
        "    hybrid_comp_mask_equalize = \"None\"\n",
        "    hybrid_comp_mask_auto_contrast = False\n",
        "    hybrid_comp_save_extra_frames = False\n",
        "    hybrid_use_video_as_mse_image = False\n",
        "\n",
        "    ##@markdown ####**Interpolation:**\n",
        "    interpolate_key_frames = False\n",
        "    interpolate_x_frames = 4\n",
        "\n",
        "    ##@markdown ####**Resume Animation:**\n",
        "    resume_from_timestring = False\n",
        "    resume_timestring = \"20220829210106\"\n",
        "\n",
        "    return locals()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9fly1RIWM_u"
      },
      "outputs": [],
      "source": [
        "## 7. Prompts ##\n",
        "\n",
        "# positive prompts\n",
        "cond_prompts = {\n",
        "    1: \"(best resolution, 4k, best detail), perfect face, latina, punk makeup, green eyes, black bikini\",\n",
        "}\n",
        "\n",
        "# negative prompts\n",
        "uncond_prompts = {\n",
        "    1: \"(lowres, bad quality), deformed body, deformed face, ugly, extra fingers, extra limbs, bad hands\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XVzhbmizWM_u"
      },
      "outputs": [],
      "source": [
        "##@markdown **Load Settings**\n",
        "override_settings_with_file = False\n",
        "settings_file = \"custom\"\n",
        "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"\n",
        "#@markdown **8. Run**\n",
        "def DeforumArgs():\n",
        "    #@markdown **Image Settings**\n",
        "    W = \"512\" #@param [512, 640, 768, 896, 1024]\n",
        "    H = 768 #@param [512, 640, 768, 896, 1024]\n",
        "    W = int(W)\n",
        "    H = int(H)\n",
        "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
        "    bit_depth_output = 8\n",
        "\n",
        "    #@markdown **Sampling Settings**\n",
        "    seed = -1 #@param\n",
        "    sampler = 'ddim' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_a\", \"dpmpp_2m\"]\n",
        "    steps = 30 #@param\n",
        "    scale = 6 #@param\n",
        "    ddim_eta = 0.0\n",
        "    dynamic_threshold = None\n",
        "    static_threshold = None\n",
        "\n",
        "    ##@markdown **Save & Display Settings**\n",
        "    save_samples = True\n",
        "    save_settings = True\n",
        "    display_samples = True\n",
        "    save_sample_per_step = False\n",
        "    show_sample_per_step = False\n",
        "\n",
        "    #@markdown **Batch Settings**\n",
        "    n_batch = 10 #@param\n",
        "    n_samples = 1\n",
        "    batch_name = \"Tofu_Diffusion_art\" #@param {type:\"string\"}\n",
        "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
        "    seed_behavior = \"iter\"\n",
        "    seed_iter_N = 1\n",
        "    make_grid = False\n",
        "    grid_rows = 2\n",
        "    outdir = get_output_folder(root.output_path, batch_name)\n",
        "\n",
        "    #@markdown **Initial Image Settings**\n",
        "    use_init = False #@param {type:\"boolean\"}\n",
        "    strength = 0.65 #@param {type:\"number\"}\n",
        "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
        "    init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
        "    add_init_noise = False\n",
        "    init_noise = 0.01\n",
        "    # Whiter areas of the mask are areas that change more\n",
        "    use_mask = False\n",
        "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
        "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\"\n",
        "    invert_mask = False\n",
        "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
        "    mask_brightness_adjust = 1.0\n",
        "    mask_contrast_adjust = 1.0\n",
        "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
        "    overlay_mask = True\n",
        "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
        "    mask_overlay_blur = 5\n",
        "\n",
        "    ##@markdown **Exposure/Contrast Conditional Settings**\n",
        "    mean_scale = 0\n",
        "    var_scale = 0\n",
        "    exposure_scale = 0\n",
        "    exposure_target = 0.5\n",
        "\n",
        "    ##@markdown **Color Match Conditional Settings**\n",
        "    colormatch_scale = 0\n",
        "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\"\n",
        "    colormatch_n_colors = 4\n",
        "    ignore_sat_weight = 0\n",
        "\n",
        "    ##@markdown **CLIP\\Aesthetics Conditional Settings**\n",
        "    clip_name = 'ViT-L/14'\n",
        "    clip_scale = 0\n",
        "    aesthetics_scale = 0\n",
        "    cutn = 1\n",
        "    cut_pow = 0.0001\n",
        "\n",
        "    ##@markdown **Other Conditional Settings**\n",
        "    init_mse_scale = 0\n",
        "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\"\n",
        "    blue_scale = 0\n",
        "\n",
        "    ##@markdown **Conditional Gradient Settings**\n",
        "    gradient_wrt = 'x0_pred'\n",
        "    gradient_add_to = 'both'\n",
        "    decode_method = 'linear'\n",
        "    grad_threshold_type = 'dynamic'\n",
        "    clamp_grad_threshold = 0.2\n",
        "    clamp_start = 0.2\n",
        "    clamp_stop = 0.01\n",
        "    grad_inject_timing = list(range(1,10))\n",
        "\n",
        "    ##@markdown **Speed vs VRAM Settings**\n",
        "    cond_uncond_sync = True\n",
        "    precision = 'autocast'\n",
        "    C = 4\n",
        "    f = 8\n",
        "\n",
        "    cond_prompt = \"\"\n",
        "    cond_prompts = \"\"\n",
        "    uncond_prompt = \"\"\n",
        "    uncond_prompts = \"\"\n",
        "    timestring = \"\"\n",
        "    init_latent = None\n",
        "    init_sample = None\n",
        "    init_sample_raw = None\n",
        "    mask_sample = None\n",
        "    init_c = None\n",
        "    seed_internal = 0\n",
        "\n",
        "    return locals()\n",
        "\n",
        "args_dict = DeforumArgs()\n",
        "anim_args_dict = DeforumAnimArgs()\n",
        "\n",
        "if override_settings_with_file:\n",
        "    load_args(args_dict, anim_args_dict, settings_file, custom_settings_file, verbose=False)\n",
        "\n",
        "args = SimpleNamespace(**args_dict)\n",
        "anim_args = SimpleNamespace(**anim_args_dict)\n",
        "\n",
        "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "args.strength = max(0.0, min(1.0, args.strength))\n",
        "\n",
        "# Load clip model if using clip guidance\n",
        "if (args.clip_scale > 0) or (args.aesthetics_scale > 0):\n",
        "    root.clip_model = clip.load(args.clip_name, jit=False)[0].eval().requires_grad_(False).to(root.device)\n",
        "    if (args.aesthetics_scale > 0):\n",
        "        root.aesthetics_model = load_aesthetics_model(args, root)\n",
        "\n",
        "if args.seed == -1:\n",
        "    args.seed = random.randint(0, 2**32 - 1)\n",
        "if not args.use_init:\n",
        "    args.init_image = None\n",
        "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
        "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
        "    args.sampler = 'klms'\n",
        "if args.sampler != 'ddim':\n",
        "    args.ddim_eta = 0\n",
        "\n",
        "if anim_args.animation_mode == 'None':\n",
        "    anim_args.max_frames = 1\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    args.use_init = True\n",
        "\n",
        "# clean up unused memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# dispatch to appropriate renderer\n",
        "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
        "    render_animation(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    render_input_video(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "elif anim_args.animation_mode == 'Interpolation':\n",
        "    render_interpolation(root, anim_args, args, cond_prompts, uncond_prompts)\n",
        "else:\n",
        "    render_image_batch(root, args, cond_prompts, uncond_prompts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('dsd')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b7e04c8a9537645cbc77fa0cbde8069bc94e341b0d5ced104651213865b24e58"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}